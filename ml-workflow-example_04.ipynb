{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example workflow of machine learning algorithm cross validation in python sci-kit learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Believe your local cv score rather than public LB score is the first principal that all kagglers should know. In previous notebook we already get involved with cross validation: we use `GridSearchCV` to search optimal hyperparameters based on cv score. \n",
    "\n",
    "This time is for calculate cv score for certain algorithm, this also could be viewed as an evaluation. This notebook's code has the following reference: https://www.kaggle.com/ogrellier/lgbm-with-words-and-chars-n-gram/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 2), (150,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X, y = iris.data[:, :2], iris.target\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate cross validation score for a given model (estimator)\n",
    "\n",
    "We can just use `cross_val_score()`, this is the simplest case where the estimator could be `fit` and `predict`. However we just get the score and don't know which part of the data is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf = LogisticRegression()\n",
    "lr_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.73333333,  0.8       ,  0.66666667,  0.8       ,  0.6       ,\n",
       "        0.73333333,  0.8       ,  0.8       ,  0.8       ,  0.86666667])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores = cross_val_score(lr_clf, X, y, scoring='accuracy', cv=10)\n",
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76000000000000001"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate cross validation score based on splited data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.model_selection._split.KFold"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "folds = KFold(n_splits=10, shuffle=True, random_state=233)\n",
    "type(folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Start cross validation . . .\n",
      "\n",
      "\t Fold 1 accuracy: 0.5333333333333333\n",
      "\t Fold 2 accuracy: 0.8666666666666667\n",
      "\t Fold 3 accuracy: 0.8\n",
      "\t Fold 4 accuracy: 0.6666666666666666\n",
      "\t Fold 5 accuracy: 0.7333333333333333\n",
      "\t Fold 6 accuracy: 0.26666666666666666\n",
      "\t Fold 7 accuracy: 0.9333333333333333\n",
      "\t Fold 8 accuracy: 0.8\n",
      "\t Fold 9 accuracy: 0.6666666666666666\n",
      "\t Fold 10 accuracy: 0.8\n",
      "\n",
      " Total CV score is 0.7066666666666667\n"
     ]
    }
   ],
   "source": [
    "print(' Start cross validation . . .\\n')\n",
    "for n_fold, (train_idx, val_idx) in enumerate(folds.split(X, y)):\n",
    "    \n",
    "    # prepare data\n",
    "    X_train, y_train, X_val, y_val = X[train_idx], y[train_idx], X[val_idx], y[val_idx]\n",
    "    \n",
    "    # fit model\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # evaluate model\n",
    "    y_pred_val = clf.predict(X_val)\n",
    "    curr_score = accuracy_score(y_val, y_pred_val)\n",
    "    scores.append(curr_score)\n",
    "    print('\\t Fold {} accuracy: {}'.format(n_fold + 1, curr_score))\n",
    "    \n",
    "print('\\n Total CV score is {}'.format(np.mean(scores)))    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
